{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7ee22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import math\n",
    "import collections\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self,split,col_index):\n",
    "        self.col_id= col_index\n",
    "        self.split_value= split\n",
    "        self.parent=None\n",
    "        self.left= None\n",
    "        self.right= None\n",
    "        \n",
    "class Tree():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.treemodel = None\n",
    "  \n",
    "    def train(self,trainData):\n",
    "        #Attributes/Last Column is class\n",
    "        self.createTree(trainData)\n",
    "        \n",
    "    \n",
    "    def createTree(self,trainData):\n",
    "        #create the tree\n",
    "        self.treemodel=build_tree(trainData,[])\n",
    "        saveTree(self.treemodel)\n",
    "        \n",
    "    def accuracy_confusion_matrix(self,testData):\n",
    "        #prints the tree confusion matrix along with the accuracy\n",
    "        build_confusion_matrix(self.treemodel,testData)\n",
    "     \n",
    "#returns the best split on the data instance along \n",
    "#with the splitted dataset and column index     \n",
    "def getBestSplit(data):\n",
    "    #set the max information gain\n",
    "    maxInfoGain = -float('inf')\n",
    "    \n",
    "    #convert to array\n",
    "    dataArray = np.asarray(data)    \n",
    "\n",
    "    #to extract rows and columns\n",
    "    dimension = np.shape(dataArray)\n",
    "    \n",
    "    #iterate through the matrix\n",
    "    for col in range(dimension[1]-1):\n",
    "       dataArray = sorted(dataArray, key=lambda x: x[col])\n",
    "       for row in range(dimension[0]-1):\n",
    "           val1=dataArray[row][col]\n",
    "           val2=dataArray[row+1][col]\n",
    "           expectedSplit = (float(val1)+float(val2))/2.0\n",
    "           infoGain,l,r= calcInfoGain(data,col,expectedSplit)\n",
    "           if(infoGain>maxInfoGain):\n",
    "                maxInfoGain=infoGain\n",
    "                best= (col,expectedSplit,l,r)\n",
    "    return best      \n",
    "     \n",
    "#This method is used to calculate the gain and returns \n",
    "#the left and right data as per the split\n",
    "def calcInfoGain(data,col,split):\n",
    "    totalLen = len(data)\n",
    "    infoGain = entropy(data)\n",
    "    \n",
    "    left_data, right_data =getDataSplit(data,split,col)\n",
    "    \n",
    "    infoGain = infoGain- (len(left_data)/totalLen * entropy(left_data))\n",
    "    infoGain = infoGain- (len(right_data)/totalLen * entropy(right_data))\n",
    "   \n",
    "    return infoGain,left_data,right_data\n",
    "    \n",
    "\n",
    "def getDataSplit(data, split, col):\n",
    "    l_data=[]\n",
    "    r_data=[]\n",
    " \n",
    "    for val in data:\n",
    "        if(val[col]<split):\n",
    "            l_data.append(val)\n",
    "        else:\n",
    "            r_data.append(val)\n",
    "    \n",
    "    return l_data,r_data\n",
    "\n",
    "#calculates the entropy of the data set provided    \n",
    "def entropy(data):\n",
    "    totalLen = len(data)\n",
    "    entropy = 0\n",
    "    group_by_class= groupby(data, lambda x:x[5])\n",
    "    for key,group in group_by_class:\n",
    "        grp_len = len(list(group))\n",
    "        entropy+= -(grp_len/totalLen)*math.log((grp_len/totalLen),2)\n",
    "    return entropy   \n",
    "           \n",
    "#this method builds the decision tree recursively until the leaf nodes are reached           \n",
    "def build_tree(data,parent_data):\n",
    "    #code to find out if the class variable is all one value\n",
    "    count=0;\n",
    "    group_by_class= groupby(data, lambda x:x[5])\n",
    "   \n",
    "   #finds out if all the instances have the same class or not\n",
    "    for key,group in group_by_class:\n",
    "        count=count+1;\n",
    "    \n",
    "    #if same class for all instances then return the leaf node class value\n",
    "    if(count==1):\n",
    "        return data[0][5];\n",
    "        \n",
    "    elif(len(data)==0):\n",
    "        #this counts all the column class variable row values and finds most common in it\n",
    "        return collections.Counter(np.asarray(data[:,5])).most_common(1)[0][0]\n",
    "    \n",
    "    else:\n",
    "        bestsplit= getBestSplit(data)\n",
    "        node = TreeNode(bestsplit[1],bestsplit[0])\n",
    "        node.left= build_tree(bestsplit[2],data)\n",
    "        node.right= build_tree(bestsplit[3],data)\n",
    "        return node\n",
    " \n",
    "#this method is used to classify the test set with the model created \n",
    "def classify(tree, row):\n",
    "    if type(tree)==str:\n",
    "        return tree\n",
    "    if row[tree.col_id]<=tree.split_value:\n",
    "        return classify(tree.left, row)\n",
    "    else:\n",
    "        return classify(tree.right, row)\n",
    "\n",
    "#this method saves the decision tree model using pickle package    \n",
    "def saveTree(tree):\n",
    "    decisionTree= deepcopy(tree)\n",
    "    pickle.dump(decisionTree,open('model.pkl','wb'))\n",
    "\n",
    "#this method creates a confusion matrix and finds accuracy for test dataset    \n",
    "def build_confusion_matrix(tree, data):\n",
    "    confusion_mat = [[0 for row in range(4)]for col in range(4)]\n",
    "    \n",
    "    total_len=len(data)\n",
    "    num_correct_instances=0;\n",
    "    num_incorrect_instances = 0;\n",
    "    \n",
    "    #map required to build the confusion matrix\n",
    "    map={'B':0,'G':1,'M':2, 'N':3}    \n",
    "    \n",
    "    for row in data:\n",
    "        actual_class = row[5]\n",
    "        predicted_class=classify(tree, row)\n",
    "        if(actual_class==predicted_class):\n",
    "            num_correct_instances=num_correct_instances+1\n",
    "            confusion_mat[map.get(actual_class)][map.get(actual_class)]=confusion_mat[map.get(actual_class)][map.get(actual_class)]+1\n",
    "        else:\n",
    "            num_incorrect_instances=num_incorrect_instances+1\n",
    "            confusion_mat[map.get(actual_class)][map.get(predicted_class)]=confusion_mat[map.get(actual_class)][map.get(predicted_class)]+1\n",
    "    \n",
    "    print(\"Accuracy of the model:\",(num_correct_instances/total_len)*100,\"%\")\n",
    "    print(\"Correct instances\",num_correct_instances)\n",
    "    print(\"Incorrect instances\",num_incorrect_instances)\n",
    "    \n",
    "    \n",
    "    print_map={0:'B',1:'G',2:'M', 3:'N'}   \n",
    "    print(\"Confusion Matrix:\")\n",
    "    \n",
    "    print(\"    B  G  M  N\")\n",
    "    \n",
    "    ind=0;\n",
    "    #printing matrix\n",
    "    for row in confusion_mat:\n",
    "        print(print_map.get(ind),\"\", row)        \n",
    "        ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150edac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
